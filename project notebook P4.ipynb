{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP 7 DSFT09 HYBRID PHASE 4\n",
    "## Mirriam Mumbua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Emotion Classification Using NLP: Analyzing Emotional Tone in Social Media and Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project overview\n",
    "### Problem Statement\n",
    "### This project aims to build an emotion classifier using the GoEmotions dataset, which includes human-labeled Reddit comments annotated for 27 emotion categories. The goal is to develop a model that can accurately classify text into one of these emotions, which can be applied to analyzing social media comments, reviews, or even customer feedback to detect emotional tone.\n",
    "\n",
    "### Dataset\n",
    "### The GoEmotions dataset was sourced from Reddit, a popular social media platform where users post comments on various topics. Specifically, the dataset consists of over 58,000 Reddit comments that were manually annotated by human labelers into 27 distinct emotion categories (such as joy, anger, sadness, curiosity, and more).The dataset was created by Google Research as part of their efforts to advance Natural Language Processing (NLP) research. The comments were collected from publicly available Reddit posts, ensuring a wide variety of topics and emotional expressions. The comments were then labeled with one or more emotions, making it a multi-label classification problem.\n",
    "\n",
    "## Objective\n",
    "### Develop a machine learning model capable of:\n",
    "\n",
    "### Multi-label emotion detection: Predicting one or more emotion categories for each Reddit comment from the 27 possible emotion classes.\n",
    "### Handling noisy and real-world text: Effectively preprocessing the text (e.g., dealing with slang, abbreviations, and varied sentence structures in Reddit comments) to ensure accurate predictions.\n",
    "### Accurate classification: Maximizing the model's performance on key metrics for multi-label classification (such as F1-score, precision, and recall) across all 27 emotion categories.\n",
    "\n",
    "## Expected Outcome\n",
    "### The final model will:\n",
    "\n",
    "### Take a Reddit comment as input.\n",
    "### Output one or more emotion labels (from the 27 possible emotions) that best represent the emotional tone of the comment.\n",
    "\n",
    "## Applications\n",
    "### This emotion detection model could be applied to:\n",
    "\n",
    "### Social media monitoring: To understand public sentiment on platforms like Reddit, Twitter, and Facebook.\n",
    "### Customer feedback analysis: For detecting emotional tone in product reviews or customer support conversations.\n",
    "### Mental health monitoring: To detect signs of distress or mental health issues in text-based communications on forums or in private messages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label       id\n",
       "0  I’m really sorry about your situation :( Altho...    25  eecwqtt\n",
       "1    It's wonderful because it's awful. At not with.     0  ed5f85d\n",
       "2  Kings fan here, good luck to you guys! Will be...    13  een27c3\n",
       "3  I didn't know that, thank you for teaching me ...    15  eelgwd1\n",
       "4  They got bored from haunting earth for thousan...    27  eem5uti"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('full_dataset/train.tsv', sep='\\t', header=None ,names=['text', 'label', 'id'])\n",
    "\n",
    "# Load the validation data\n",
    "dev_data = pd.read_csv('full_dataset/dev.tsv', sep='\\t', header=None,names=['text', 'label', 'id'])\n",
    "# test data \n",
    "test_data = pd.read_csv('full_dataset/test.tsv', sep='\\t', header=None,names=['text', 'label', 'id'])\n",
    "\n",
    "train_data.head()\n",
    "dev_data.head()\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_emotion = {}\n",
    "with open('full_dataset/emotions.txt', 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        label_to_emotion[idx] = line.strip()\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
